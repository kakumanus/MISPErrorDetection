{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Classifiers and XGBoost.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9C3Xssupgc9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import log_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"perfect_out2.csv\")"
      ],
      "metadata": {
        "id": "7GjfbzUspyEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data =  data[data[\"prob_threshold\"] == 1.0]"
      ],
      "metadata": {
        "id": "T9iXmLGIp1dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "def createIndexer():\n",
        "  indexer = Counter()\n",
        "  index = 0\n",
        "\n",
        "  for tag in data[\"tag_name\"]:\n",
        "    # check if we have already given this tag name an index\n",
        "    if tag not in indexer:\n",
        "      # map tag to index\n",
        "      indexer[tag] = index\n",
        "      \n",
        "      # increment the index for the next tag name\n",
        "      index += 1\n",
        "  \n",
        "  return indexer\n",
        "indexer = createIndexer()\n",
        "indexer"
      ],
      "metadata": {
        "id": "Wi1JuXSyp2mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = data[[\"tag_name\", \"tag_prob\"]]\n",
        "y_data = data[\"tag_resp\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "IS9Jyy-3p-NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert1Hot(data):\n",
        "  # new data will have first cat_count - 1 columns as one hot encoding \n",
        "  # for which kind of semantic unit we are dealing with\n",
        "  # the last column will be the probabilit of the semantic unit\n",
        "  new_data = np.zeros((data.shape[0], len(indexer) + 1))\n",
        "\n",
        "  # go through all examples and add 1 where relavant\n",
        "  for idx in range(data.shape[0]):\n",
        "    # copying the probability\n",
        "    new_data[idx, -1] = data[idx, 1]\n",
        "\n",
        "    # column index\n",
        "    col_idx = indexer[data[idx, 0]]\n",
        "\n",
        "    # setting the one hot encoding\n",
        "    new_data[idx, col_idx] = 1\n",
        "  \n",
        "  return new_data"
      ],
      "metadata": {
        "id": "CqwVM2K9p_Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = x_train.to_numpy(), y_train.to_numpy()\n",
        "x_test, y_test = x_test.to_numpy(), y_test.to_numpy()\n",
        "\n",
        "y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
        "y_test = np.reshape(y_test, (y_test.shape[0], 1))"
      ],
      "metadata": {
        "id": "D0R-bR36qDIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "#clf = clf.fit(X_train.to_numpy().reshape(-1,1), y_train)\n",
        "clf = clf.fit(x_train, y_train)\n",
        "y_pred= clf.predict(x_test)\n"
      ],
      "metadata": {
        "id": "aKCNEGpjqQ_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_loss(y_test,y_pred)"
      ],
      "metadata": {
        "id": "rkWnXheeqR1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "Vz4qwk-zqbwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "#clf.fit(X_train.to_numpy().reshape(-1,1), y_train)\n",
        "clf.fit(x_train, y_train)\n",
        "y_pred= clf.predict(x_test)"
      ],
      "metadata": {
        "id": "i5uqJODdqckF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_loss(y_test,y_pred)"
      ],
      "metadata": {
        "id": "8lY5Q-v2qe0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "VnCX4tpuqoEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logisticRegr = LogisticRegression()\n",
        "#logisticRegr.fit(X_train.to_numpy().reshape(-1,1), y_train)\n",
        "logisticRegr.fit(x_train, y_train)\n",
        "y_pred = logisticRegr.predict(x_test)"
      ],
      "metadata": {
        "id": "XLXTdEIqqq0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_loss(y_test,y_pred)"
      ],
      "metadata": {
        "id": "2hPPLALoqrwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "hs43e9NBrBFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "#clf = gnb.fit(X_train.to_numpy().reshape(-1,1), y_train)\n",
        "clf = gnb.fit(x_train, y_train)\n",
        "y_pred= clf.predict(x_test)"
      ],
      "metadata": {
        "id": "shqdd3PWrB5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_loss(y_test,y_pred)"
      ],
      "metadata": {
        "id": "WuZJWxPQrgTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "cEHGVudfrim9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=5)\n",
        "#neigh = neigh.fit(X_train.to_numpy().reshape(-1,1), y_train)\n",
        "neigh = neigh.fit(x_train, y_train)\n",
        "y_pred = neigh.predict(x_test)"
      ],
      "metadata": {
        "id": "28RXSs07rjUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_loss(y_test,y_pred)"
      ],
      "metadata": {
        "id": "qaHtruAJrn63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "cqJaS85NrreY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot feature importance manually\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from matplotlib import pyplot\n",
        "# load data\n",
        "#dataset = loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
        "# split data into X and y\n",
        "#X = dataset[:,0:8]\n",
        "#y = dataset[:,8]\n",
        "# fit model no training data\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "# feature importance\n",
        "print(model.feature_importances_)\n",
        "# plot\n",
        "pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "JxAp6EQYrxbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import plot_importance\n",
        "plot_importance(model)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "jCcsvqL5r1k-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}